{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shapely.geometry import Polygon\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import *\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "\n",
    "class WindowTiler:\n",
    "\n",
    "### Paramters #################################################################\n",
    "    MASK_REGION = ( (750,600), (750,400), (1280,400), (1280,600) )\n",
    "    TOP_SIZE = 70\n",
    "    BOTTOM_SIZE = 150  \n",
    "    OVERLAP = 0.92\n",
    "\n",
    "### Function Set ##############################################################\n",
    "    \n",
    "### Initialization, compute polygon, roi, left=start_point, right=stop_point, top=start_size, bottom=stop_size\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.poly = Polygon(self.MASK_REGION)\n",
    "        roi = np.array(self.MASK_REGION)\n",
    "        self.roi = roi\n",
    "        self.left = np.amin(roi, axis=0)[0]\n",
    "        self.right = np.amax(roi, axis=0)[0]\n",
    "        self.top = np.amin(roi, axis=0)[1]\n",
    "        self.bottom = np.amax(roi, axis=0)[1]\n",
    "\n",
    "### Define a tiler function to generate proportional steps via vertical and horizontal iterator\n",
    "    def tiler(self, start_point, stop_point, start_size, stop_size):\n",
    "        i = start_point + start_size / 2\n",
    "        size = start_size\n",
    "        size_slope = float(stop_size - start_size) / float(stop_point - start_point)\n",
    "        result = []\n",
    "        while i < stop_point - stop_size / 2:\n",
    "            result.append((int(i),int(size)))\n",
    "            size = int(start_size + (i - start_point) * size_slope)\n",
    "            i = int(i + size * (1 - self.OVERLAP))\n",
    "        return result\n",
    "\n",
    "### Generate filter (windows)\n",
    "    def generate_windows(self):\n",
    "    ### Compute regions\n",
    "        regions = []\n",
    "        vertical = self.tiler(self.top, self.bottom, self.TOP_SIZE, self.BOTTOM_SIZE)  # 纵向计算\n",
    "        for v in vertical:\n",
    "            horizontal = self.tiler(self.left, self.right, v[1], v[1])                #横向计算\n",
    "            for h in horizontal:\n",
    "                center = (h[0], v[0])\n",
    "                size = (h[1], v[1])\n",
    "                regions.append((center, size))\n",
    "    ### Compute roi_area and fill polygon\n",
    "        if len(self.image.shape) > 2:\n",
    "            channel_count = self.image.shape[2]  \n",
    "            ignore_mask_color = (255,) * channel_count\n",
    "        else:\n",
    "            ignore_mask_color = 255\n",
    "        mask = np.zeros_like(self.image) \n",
    "        cv2.fillPoly(mask, [self.roi], ignore_mask_color)\n",
    "        roi_image = cv2.bitwise_and(self.image, mask)\n",
    "    ### Generate windows\n",
    "        windows = []\n",
    "        for r in regions:\n",
    "            center = r[0]\n",
    "            size = r[1]\n",
    "            left = int(center[1] - size[1]/2)\n",
    "            right = int(center[1] + size[1]/2)\n",
    "            top = int(center[0] - size[0]/2)\n",
    "            bottom = int(center[0] + size[0]/2)\n",
    "            poly = ((bottom,left), (top,left), (top,right), (bottom,right))\n",
    "            poly = Polygon(poly)\n",
    "            intersects = poly.intersects(self.poly)\n",
    "            if intersects:\n",
    "                sub_image = roi_image[left:right,top:bottom]\n",
    "                windows.append((center, size, sub_image))\n",
    "        return windows\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class HeatMap:\n",
    "    \n",
    "### Initialization\n",
    "    def __init__(self, image):\n",
    "        self.image = np.array(image)\n",
    "        self.height = self.image.shape[0]\n",
    "        self.width = self.image.shape[1]\n",
    "\n",
    "### 暂时并没什么用\n",
    "    def mono_overlay(self, points, radius, intensity):    # intensity从外部引入\n",
    "        k_size = 3 * radius\n",
    "        kernel = np.ones((k_size, k_size), np.float32) / (k_size**2)\n",
    "        mono_overlay = np.zeros((self.height, self.width), np.uint8)\n",
    "        for p in points:\n",
    "            p = (int(p[0]), int(p[1]))\n",
    "            ol = np.zeros((self.height, self.width), np.uint8)\n",
    "            cv2.circle(ol, p, radius, intensity, -1)\n",
    "            ol = cv2.filter2D(ol, -1, kernel)\n",
    "            cv2.addWeighted(ol, 1.0, overlay, 1.0, 0, color_overlay)\n",
    "        return mono_overlay\n",
    "    \n",
    "### 暂时并没什么用\n",
    "    def color_overlay(self, points, radius, color):    # color从外部引入\n",
    "        k_size = 3 * radius\n",
    "        kernel = np.ones((k_size, k_size), np.float32) / (k_size**2)\n",
    "        color_overlay = np.zeros((self.height, self.width, 3), np.uint8)\n",
    "        for p in points:\n",
    "            p = (int(p[0]), int(p[1]))\n",
    "            ol = np.zeros((self.height, self.width, 3), np.uint8)\n",
    "            cv2.circle(ol, p, radius, color, -1)\n",
    "            ol = cv2.filter2D(ol, -1, kernel)\n",
    "            cv2.addWeighted(ol, 1.0, overlay, 1.0, 0, color_overlay)\n",
    "        return color_overlay\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class processing:\n",
    "\n",
    "### Paramters #################################################################\n",
    "\n",
    "    PICKLE_FILE = 'classified_data.p'\n",
    "\n",
    "### Function Set ##############################################################\t\n",
    "\n",
    "### Load classified data    \n",
    "    def load_classifier(self):\n",
    "        self.classifier = pickle.load(open(self.PICKLE_FILE, 'rb'))\n",
    "\n",
    "### Load image\n",
    "    def load_file(self, filename):\n",
    "        self.image = mpimg.imread(filename)\n",
    "        \n",
    "### sort by descending order of array, swap data\n",
    "    def sort(self, data):\n",
    "        return (data[1], data[0])\n",
    "\n",
    "### 用于car_points_heatmap和intensity_heatmap\n",
    "    def car_points(self):\n",
    "        wt = WindowTiler(self.image)\n",
    "        windows = wt.generate_windows()\n",
    "        points = []\n",
    "        for w in windows:\n",
    "            center = self.sort(w[0])\n",
    "            bounds = w[1]\n",
    "            ll = (int(center[0] - bounds[0] / 2), int(center[1] - bounds[1] / 2))\n",
    "            ur = (int(center[0] + bounds[0] / 2), int(center[1] + bounds[1] / 2))\n",
    "            corners = (ll, ur)\n",
    "            image = w[2]\n",
    "            is_car = self.classifier.classify_new(image)\n",
    "            if is_car[2] == 1.0:\n",
    "                points.append((center, corners))\n",
    "        return points\n",
    "\n",
    "### 暂时并没什么用\n",
    "    def get_region_centers(self, regions):\n",
    "        return [self.sort(r[0]) for r in regions]\n",
    "\n",
    "### 暂时并没什么用\n",
    "### Generate a mono overlay\n",
    "    def intensity_heatmap(self, radius, intensity):\n",
    "        heat_map = HeatMap(self.image)\n",
    "        points = [self.sort(r[0]) for r in self.car_points()]\n",
    "        mono_overlay = heat_map.mono_overlay(points, radius, intensity)\n",
    "        return mono_overlay\n",
    "\n",
    "### Generate a clolor overlay\n",
    "    def car_points_heatmap(self, radius, color):\n",
    "        heat_map = HeatMap(self.image)\n",
    "        points = [self.sort(r[0]) for r in self.car_points()]\n",
    "        color_overlay = heat_map.color_overlay(points, radius, color)\n",
    "        return color_overlay\n",
    "    \n",
    "### Attach a overlay of head map\n",
    "    def overlay(self, image, alpha):\n",
    "        cv2.addWeighted(image, alpha, self.image, 1.0, 0, self.image)\n",
    "        return self.image\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "p = processing()\n",
    "p.load_classifier()\n",
    "p.load_file('test_images/test4.jpg')\n",
    "cph = p.car_points_heatmap(20, (100,100,0))\n",
    "plt.imshow(p.overlay(cph, alpha=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "\n",
    "### Paramters #################################################################\n",
    "\n",
    "### combined_spatial()\n",
    "    SPATIAL_SIZE = (32, 32)\n",
    "    HLS_BINS = 512 \n",
    "    HLS_BIN_RANGE = (0,255)\n",
    "    HOG_ORIENTATIONS = 9\n",
    "    HOG_PIXELS_PER_CELL = (8,8)\n",
    "    HOG_CELLS_PER_BLOCK = (2,2)\n",
    "### 用于load()\n",
    "    IMAGE_SIZE = (64, 64)\n",
    "    TEST_FRACTION = 0.2\n",
    "    RANDOM_STATE = 12345\n",
    "### train()\n",
    "    SVC_KERNEL = 'rbf'\n",
    "    SVC_C_VALUE = 2.0\n",
    "    DT_MIN_SAMPLES_SPLIT = 40\n",
    "### store(), define path 'classified_data.p' to save classified data\n",
    "    PICKLE_FILE = 'classified_data.p'\n",
    "\n",
    "### Function Set ##############################################################\n",
    "\n",
    "### Initialization, vehicle=true, non-vehicle=false\n",
    "    def __init__(self, true_path, false_path):\n",
    "        self.true_path = true_path\n",
    "        self.false_path = false_path\n",
    "\n",
    "### Combine spatial function for load data\n",
    "    def combined_spatial(self, image):\n",
    "    ### compute spatial of image\n",
    "        spatial = cv2.resize(image, self.SPATIAL_SIZE).ravel()\n",
    "    ### compute spatial with hls\n",
    "        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        h_hist = np.histogram(hls[:,:,0], bins=self.HLS_BINS, range=self.HLS_BIN_RANGE)\n",
    "        s_hist = np.histogram(hls[:,:,2], bins=self.HLS_BINS, range=self.HLS_BIN_RANGE)\n",
    "        hls = np.concatenate((h_hist[0], s_hist[0]))\n",
    "    ### compute spatial with hog\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        hogs = hog(gray, orientations=self.HOG_ORIENTATIONS, pixels_per_cell=self.HOG_PIXELS_PER_CELL, cells_per_block=self.HOG_CELLS_PER_BLOCK, transform_sqrt=True, visualise=False, feature_vector=True)\n",
    "        combined_spatial = np.concatenate((spatial, hls, hogs))\n",
    "        return combined_spatial\n",
    "\n",
    "### Load and split data\n",
    "    def load(self):\n",
    "    ### Define the path of vehicle folder and non-vehicle folder\n",
    "        true_paths = glob2.glob(self.true_path)\n",
    "        false_paths = glob2.glob(self.false_path)\n",
    "    ### Define features set and labels set for load images and store data\n",
    "        features = []\n",
    "        labels = []\n",
    "    ### Load vehicle images and store features and labels, vehicle=1.0\n",
    "        for filename in true_paths:\n",
    "            image = cv2.resize(mpimg.imread(filename), self.IMAGE_SIZE)\n",
    "            hls_hog = self.combined_spatial(image)\n",
    "            features.append(hls_hog)\n",
    "            labels.append(1.0)\n",
    "    ### Load non-vehicle images and store features and labels, non-vehicle=0.0\n",
    "        for filename in false_paths:\n",
    "            image = cv2.resize(mpimg.imread(filename), self.IMAGE_SIZE)\n",
    "            hls_hog = self.combined_spatial(image)\n",
    "            features.append(hls_hog)\n",
    "            labels.append(0.0)\n",
    "    ### Normalize features\n",
    "        features=np.array(features, np.float32)\n",
    "        self.scaler = StandardScaler().fit(features)\n",
    "        features = self.scaler.transform(features)\n",
    "    ### Split to train features, train labels, test features, test labels, store train labels and test labels as numpy array\n",
    "        self.train_features, self.test_features, self.train_labels, self.test_labels = train_test_split(features, labels, test_size=self.TEST_FRACTION, random_state=self.RANDOM_STATE)\n",
    "        self.train_labels = np.array(self.train_labels, np.float32)\n",
    "        self.test_labels = np.array(self.test_labels, np.float32)\n",
    "        return self\n",
    "    \n",
    "    def combined_prediction(self, list_svc, list_dt):\n",
    "        prediction = []\n",
    "        for index, val_svc in enumerate(list_svc):\n",
    "            val_dt = list_dt[index]\n",
    "            if val_svc == 1.0 or val_dt == 1.0:\n",
    "                prediction.append(1.0)\n",
    "            else:\n",
    "                prediction.append(0.0)\n",
    "        return prediction\n",
    "    \n",
    "    def classify_new(self, image):\n",
    "        image = cv2.resize(image, self.IMAGE_SIZE)\n",
    "        hls_hog = self.combined_spatial(image)\n",
    "        features=np.array(hls_hog, np.float32)\n",
    "        self.scaler = StandardScaler().fit(features)\n",
    "        features = self.scaler.transform(features)\n",
    "        self.svc_classifier = SVC(kernel=self.SVC_KERNEL,C=self.SVC_C_VALUE)\n",
    "        self.svc_classifier.fit(self.train_features, self.train_labels)\n",
    "        svc_prediction = self.svc_classifier.predict(features)\n",
    "        self.dt_classifier = DecisionTreeClassifier(min_samples_split=self.DT_MIN_SAMPLES_SPLIT)\n",
    "        self.dt_classifier.fit(self.train_features, self.train_labels)\n",
    "        dt_prediction = self.dt_classifier.predict(features)\n",
    "        composite_prediction = self.combined_prediction(svc_prediction, dt_prediction)\n",
    "        return np.array([svc_prediction, dt_prediction, composite_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
