{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking\n",
    "- by NK Zou\n",
    "  \n",
    "### Table of content\n",
    "1- Classifier with HLS & HOG, SVC & DecisionTree  \n",
    "2- Sliding Window Search  \n",
    "3- Video Implementation  \n",
    "\n",
    "1- Classifier 分类器\n",
    "2- Proportional Steps 比例步骤\n",
    "3- Window Tiling 窗口平铺\n",
    "4- Heat Maps 热图\n",
    "5- Processing Still Images 处理静态图像\n",
    "6- Heat Map Combinations 热图组合\n",
    "7- Vehicle Tracking 车辆跟踪\n",
    "8- Bounding Box 边界框\n",
    "9- Vehicle Detector 探测车辆\n",
    "\n",
    "分类器\n",
    "Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector.\n",
    "Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "\n",
    "窗口平铺\n",
    "Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "\n",
    "热图，探测车辆\n",
    "Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Classifier with HLS & HOG, SVC & DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "'''\n",
    "1- All of self.attribute can be shared under same class, add self. as prefix when use prameter in function\n",
    "   class的作用在于在同一个clas内的所有self.attribute可以共享，parameters则在引用时添加前缀self.即可\n",
    "2- If subfolder has many folders in the path, use ** instead of all folder names, like * instead of all file names\n",
    "   如果路径中的包含多个子文件夹，用 **  代替所有文件夹名称， 正如用 * 代替所有文件名一样\n",
    "3- __MACOSX and .DS_Store are useless files for windows users, can remove them and set path as 'folder/**/*.png'\n",
    "   __MACOSX 和 .DS_Store 都是Mac压缩时为方便预览而生成的垃圾文件，windows用户可以直接删除，把路径改为 'folder/**/*.png'\n",
    "4- In decisiontreeclassifier, the feature in the higher level node has a greater contribution to the final prediction\n",
    "   一个决策树，节点在越高的分支，相应的特征对最终预测结果的贡献越大。这里的大，是指影响输入数据集的比例比较大\n",
    "5- feature_importances_ is an attribute of sklearn, _ is a connector between words, but last _ is not implication in here\n",
    "   feature_importances_ 只是sklearn的一个属性，下划线代表两个单词间的连接符，但最后一个下划线在这里没有特殊意义，只是一个习惯\n",
    "'''\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "### Paramters #################################################################\n",
    "\n",
    "### combined_spatial()\n",
    "    SPATIAL_SIZE = (32, 32)\n",
    "    HLS_BINS = 512 \n",
    "    HLS_BIN_RANGE = (0,255)\n",
    "    HOG_ORIENTATIONS = 9\n",
    "    HOG_PIXELS_PER_CELL = (8,8)\n",
    "    HOG_CELLS_PER_BLOCK = (2,2)\n",
    "### 用于load()\n",
    "    IMAGE_SIZE = (64, 64)\n",
    "    TEST_FRACTION = 0.2\n",
    "    RANDOM_STATE = 12345\n",
    "### train()\n",
    "    SVC_KERNEL = 'rbf'\n",
    "    SVC_C_VALUE = 2.0\n",
    "    DT_MIN_SAMPLES_SPLIT = 40\n",
    "### store(), define path 'classified_data.p' to save classified data\n",
    "    PICKLE_FILE = 'classified_data.p'\n",
    "\n",
    "### Function Set ##############################################################\n",
    "\n",
    "### Initialization, vehicle=true, non-vehicle=false\n",
    "    def __init__(self, true_path, false_path):\n",
    "        self.true_path = true_path\n",
    "        self.false_path = false_path\n",
    "\n",
    "### Combine spatial function for load data\n",
    "    def combined_spatial(self, image):\n",
    "    ### compute spatial of image\n",
    "        spatial = cv2.resize(image, self.SPATIAL_SIZE).ravel()\n",
    "    ### compute spatial with hls\n",
    "        hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "        h_hist = np.histogram(hls[:,:,0], bins=self.HLS_BINS, range=self.HLS_BIN_RANGE)\n",
    "        s_hist = np.histogram(hls[:,:,2], bins=self.HLS_BINS, range=self.HLS_BIN_RANGE)\n",
    "        hls = np.concatenate((h_hist[0], s_hist[0]))\n",
    "    ### compute spatial with hog\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        hogs = hog(gray, orientations=self.HOG_ORIENTATIONS, pixels_per_cell=self.HOG_PIXELS_PER_CELL, cells_per_block=self.HOG_CELLS_PER_BLOCK, transform_sqrt=True, visualise=False, feature_vector=True)\n",
    "        combined_spatial = np.concatenate((spatial, hls, hogs))\n",
    "        return combined_spatial\n",
    "\n",
    "### Load and split data\n",
    "    def load(self):\n",
    "    ### Define the path of vehicle folder and non-vehicle folder\n",
    "        true_paths = glob2.glob(self.true_path)\n",
    "        false_paths = glob2.glob(self.false_path)\n",
    "    ### Define features set and labels set for load images and store data\n",
    "        features = []\n",
    "        labels = []\n",
    "    ### Load vehicle images and store features and labels, vehicle=1.0\n",
    "        for filename in true_paths:\n",
    "            image = cv2.resize(mpimg.imread(filename), self.IMAGE_SIZE)\n",
    "            hls_hog = self.combined_spatial(image)\n",
    "            features.append(hls_hog)\n",
    "            labels.append(1.0)\n",
    "    ### Load non-vehicle images and store features and labels, non-vehicle=0.0\n",
    "        for filename in false_paths:\n",
    "            image = cv2.resize(mpimg.imread(filename), self.IMAGE_SIZE)\n",
    "            hls_hog = self.combined_spatial(image)\n",
    "            features.append(hls_hog)\n",
    "            labels.append(0.0)\n",
    "    ### Normalize features. self.scaler is a glbal attribute in this class because their have prefix (self.)\n",
    "        features=np.array(features, np.float32)\n",
    "        self.scaler = StandardScaler().fit(features)\n",
    "        features = self.scaler.transform(features)\n",
    "    ### Split to train features, train labels, test features, test labels, store train labels and test labels as numpy array\n",
    "        self.train_features, self.test_features, self.train_labels, self.test_labels = train_test_split(features, labels, test_size=self.TEST_FRACTION, random_state=self.RANDOM_STATE)\n",
    "        self.train_labels = np.array(self.train_labels, np.float32)\n",
    "        self.test_labels = np.array(self.test_labels, np.float32)\n",
    "        return self\n",
    "\n",
    "### Train data with SVC and Decision Tree\n",
    "### self.svc_classifier and self.dt_classifier are glbal attribute in this class because their have prefix (self.)\n",
    "### Both of self.svc_classifier and dt_classifier need to use .fit() before testing\n",
    "    def train(self):\n",
    "        self.svc_classifier = SVC(kernel=self.SVC_KERNEL,C=self.SVC_C_VALUE)\n",
    "        self.svc_classifier.fit(self.train_features, self.train_labels)\n",
    "        self.dt_classifier = DecisionTreeClassifier(min_samples_split=self.DT_MIN_SAMPLES_SPLIT)\n",
    "        self.dt_classifier.fit(self.train_features, self.train_labels)\n",
    "        return self\n",
    "\n",
    "### Combine prediction function for testing, vehicle=1.0, non-vehicle=0.0\n",
    "    def combined_prediction(self, list_svc, list_dt):\n",
    "        prediction = []\n",
    "        for index, val_svc in enumerate(list_svc):\n",
    "            val_dt = list_dt[index]\n",
    "            if val_svc == 1.0 or val_dt == 1.0:\n",
    "                prediction.append(1.0)\n",
    "            else:\n",
    "                prediction.append(0.0)\n",
    "        return prediction\n",
    "\n",
    "### Test trained data set, compute accuracy\n",
    "    def test(self):\n",
    "        svc_prediction = self.svc_classifier.predict(self.test_features)\n",
    "        svc_accuracy = accuracy_score(svc_prediction, self.test_labels)\n",
    "        dt_prediction = self.dt_classifier.predict(self.test_features)\n",
    "        dt_accuracy = accuracy_score(dt_prediction, self.test_labels)\n",
    "        composited_prediction = self.combined_prediction(svc_prediction, dt_prediction)\n",
    "        composited_accuracy = accuracy_score(composited_prediction, self.test_labels)\n",
    "        return np.array([svc_accuracy, dt_accuracy, composited_accuracy])\n",
    "\n",
    "### Store classified data\n",
    "    def store(self):\n",
    "        pickle.dump(self, open(self.PICKLE_FILE, 'wb'))\n",
    "        \n",
    "### Object identification, just like combine fuction of load and test\n",
    "    def identificator(self, image):\n",
    "        image = cv2.resize(image, self.IMAGE_SIZE)\n",
    "        hls_hog = self.combined_spatial(image)\n",
    "        features=np.array(hls_hog, np.float32)\n",
    "        features = self.scaler.transform(features)\n",
    "        svc_prediction = self.svc_classifier.predict(features)\n",
    "        dt_prediction = self.dt_classifier.predict(features)\n",
    "        composite_prediction = self.combined_prediction(svc_prediction, dt_prediction)\n",
    "        return np.array([svc_prediction, dt_prediction, composite_prediction])\n",
    "\n",
    "### Classify data #############################################################\n",
    "classifier = Classifier('vehicles/**/*.png', 'non-vehicles/**/*.png')        \n",
    "print(classifier.load().train().test())\n",
    "classifier.store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Sliding Window Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.1- Describe how (and identify where in your code) you implemented a sliding window search. How did you decide what scales to search and how much to overlap windows?\n",
    "  \n",
    "# A sliding window approach has been implemented, where overlapping tiles in each test image are classified as vehicle or non-vehicle. Some justification has been given for the particular implementation chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.2- Show some examples of test images to demonstrate how your pipeline is working. How did you optimize the performance of your classifier?\n",
    "  \n",
    "# Some discussion is given around how you improved the reliability of the classifier i.e., fewer false positives and more reliable car detections (this could be things like choice of feature vector, thresholding the decision function, hard negative mining etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Video Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3.1- Provide a link to your final video output. Your pipeline should perform reasonably well on the entire project video (somewhat wobbly or unstable bounding boxes are ok as long as you are identifying the vehicles most of the time with minimal false positives.)\n",
    "  \n",
    "# The sliding-window search plus classifier has been used to search for and identify vehicles in the videos provided. Video output has been generated with detected vehicle positions drawn (bounding boxes, circles, cubes, etc.) on each frame of video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.2- Describe how (and identify where in your code) you implemented some kind of filter for false positives and some method for combining overlapping bounding boxes.\n",
    "  \n",
    "# A method, such as requiring that a detection be found at or near the same position in several subsequent frames, (could be a heat map showing the location of repeat detections) is implemented as a means of rejecting false positives, and this demonstrably reduces the number of false positives. Same or similar method used to draw bounding boxes (or circles, cubes, etc.) around high-confidence detections where multiple overlapping detections occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
